from langchain_core.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
from prompts import PHARMA_PROMPT
from dotenv import load_dotenv

load_dotenv()

# Configure the LLM (Gemini â€“ gratuit)
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0.3
)


# Prompt
prompt = PromptTemplate(
    input_variables=["symptoms"],
    template=PHARMA_PROMPT
)

# âœ… Nouvelle chain (LangChain v1+)
chain = prompt | llm


def get_pharma_advice(symptoms: str) -> str:
    response = chain.invoke({"symptoms": symptoms})
    return response.content


if __name__ == "__main__":
    print("ğŸ©º PharmaBot Console")
    print("Tape 'exit' pour quitter\n")

    while True:
        user_input = input("ğŸ‘¤ DÃ©cris tes symptÃ´mes : ")

        if user_input.lower() == "exit":
            print("ğŸ‘‹ Au revoir!")
            break

        advice = get_pharma_advice(user_input)
        print("\nğŸ’Š PharmaBot :")
        print(advice)
        print("-" * 50)
