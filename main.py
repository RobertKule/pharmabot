"""
PharmaBot Console
Assistant d'orientation pharmaceutique en console
- Utilise LangChain v1+ (Runnable)
- ModÃ¨le Gemini gratuit
- MÃ©moire de conversation en RAM
"""

# =========================
# Imports LangChain & utils
# =========================

# Pour crÃ©er un prompt structurÃ©
from langchain_core.prompts import PromptTemplate

# ModÃ¨le Gemini (Google)
from langchain_google_genai import ChatGoogleGenerativeAI

# Chargement du prompt principal
from prompts import PHARMA_PROMPT

# Gestion des variables d'environnement (.env)
from dotenv import load_dotenv

# =========================
# Imports pour la mÃ©moire
# =========================

# Historique de conversation en mÃ©moire (RAM)
from langchain_core.chat_history import InMemoryChatMessageHistory

# Wrapper pour ajouter la mÃ©moire Ã  une chain Runnable
from langchain_core.runnables.history import RunnableWithMessageHistory


# =========================
# Chargement des variables d'environnement
# =========================

# Charge GOOGLE_API_KEY depuis le fichier .env
load_dotenv()


# =========================
# Configuration du LLM
# =========================

# Initialisation du modÃ¨le Gemini
# temperature basse = rÃ©ponses calmes, factuelles (important en santÃ©)
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0.3
)


# =========================
# CrÃ©ation du prompt
# =========================

# PromptTemplate permet d'injecter dynamiquement les symptÃ´mes utilisateur
prompt = PromptTemplate(
    input_variables=["symptoms", "history"],
    template=PHARMA_PROMPT
)


# =========================
# CrÃ©ation de la chain LangChain (API moderne)
# =========================

# Ici on compose simplement :
# prompt -> LLM
chain = prompt | llm


# =========================
# Ajout de la mÃ©moire
# =========================

# Stockage de l'historique de conversation en RAM
# (rÃ©initialisÃ© Ã  chaque redÃ©marrage du programme)
chat_history = InMemoryChatMessageHistory()

# On enveloppe la chain avec une mÃ©moire conversationnelle
chain_with_memory = RunnableWithMessageHistory(
    chain,
    # Une fonction qui retourne l'historique selon l'id de session
    lambda session_id: chat_history,
    # ClÃ© d'entrÃ©e utilisateur
    input_messages_key="symptoms",
    # ClÃ© interne utilisÃ©e pour l'historique
    history_messages_key="history",
)


# =========================
# Fonction principale de rÃ©ponse
# =========================

def get_pharma_advice(symptoms: str) -> str:
    """
    Envoie les symptÃ´mes Ã  l'IA et retourne la rÃ©ponse textuelle.
    La mÃ©moire est automatiquement prise en compte.
    """
    response = chain_with_memory.invoke(
        {"symptoms": symptoms},
        # session_id permet de garder la mÃªme mÃ©moire
        config={"configurable": {"session_id": "pharmabot_console"}}
    )
    return response.content


# =========================
# Boucle principale (console)
# =========================

if __name__ == "__main__":
    print("ğŸ©º PharmaBot Console")
    print("Tape 'exit' pour quitter\n")

    while True:
        # EntrÃ©e utilisateur
        user_input = input("ğŸ‘¤ DÃ©cris tes symptÃ´mes : ")

        # Condition de sortie
        if user_input.lower() == "exit":
            print("ğŸ‘‹ Au revoir!")
            break

        # Appel de l'IA
        advice = get_pharma_advice(user_input)

        # Affichage de la rÃ©ponse
        print("\nğŸ’Š PharmaBot :")
        print(advice)
        print("-" * 50)
