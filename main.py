# -*- coding: utf-8 -*-
# main.py
# =========================
# PharmaBot Console
# =========================

"""
PharmaBot Console
Assistant d'orientation pharmaceutique en console

- LangChain v1+ (Runnable API)
- ModÃ¨le Gemini gratuit
- MÃ©moire de conversation en RAM
- Apprentissage "learn by doing"
"""

# =========================
# Imports de base
# =========================

from dotenv import load_dotenv

# Prompt structurÃ©
from langchain_core.prompts import PromptTemplate

# ModÃ¨le Gemini (Google)
from langchain_google_genai import ChatGoogleGenerativeAI

# Prompt mÃ©tier
from prompts import PHARMA_PROMPT


# =========================
# Imports mÃ©moire (LangChain v1+)
# =========================

# Historique de conversation en RAM
from langchain_core.chat_history import InMemoryChatMessageHistory

# Wrapper pour ajouter la mÃ©moire Ã  une chain
from langchain_core.runnables.history import RunnableWithMessageHistory
# =========================
# Imports spÃ©cifiques LLM Google Gemini
from langchain_google_genai.chat_models import ChatGoogleGenerativeAI
from langchain_google_genai.chat_models import ChatGoogleGenerativeAIError

# =========================
# Chargement des variables d'environnement
# =========================

# Charge GOOGLE_API_KEY depuis .env
load_dotenv()


# =========================
# Configuration du LLM
# =========================

# Gemini Flash : rapide, gratuit, suffisant pour ce projet
llm = ChatGoogleGenerativeAI(
    # model="gemini-2.5-flash",
    model="gemma-3-1b-it",
    temperature=0.3  # faible = rÃ©ponses calmes et prudentes
)


# =========================
# CrÃ©ation du prompt
# =========================

# Le prompt reÃ§oit :
# - symptoms : entrÃ©e utilisateur
# - history  : historique de la conversation
prompt = PromptTemplate(
    input_variables=["symptoms", "history"],
    template=PHARMA_PROMPT
)


# =========================
# CrÃ©ation de la chain de base
# =========================

# Prompt â†’ LLM
base_chain = prompt | llm


# =========================
# Ajout de la mÃ©moire
# =========================

# Historique stockÃ© en RAM (session console)
chat_history = InMemoryChatMessageHistory()

# Chain avec mÃ©moire
chain_with_memory = RunnableWithMessageHistory(
    base_chain,
    lambda session_id: chat_history,   # une seule session
    input_messages_key="symptoms",
    history_messages_key="history"
)


# =========================
# Fonction principale
# =========================

def get_pharma_advice(symptoms: str) -> str:
    """
    Envoie les symptÃ´mes Ã  l'IA
    + conserve l'historique
    """
    try:
        response = chain_with_memory.invoke(
            {"symptoms": symptoms},
            config={
                "configurable": {
                    "session_id": "pharmabot_console"
                }
            }
        )
        return response.content
    except ChatGoogleGenerativeAIError as e:
        return "âš ï¸ Le quota gratuit du modÃ¨le Gemini est Ã©puisÃ© pour aujourd'hui. Veuillez rÃ©essayer plus tard ou envisager un plan payant."


# =========================
# Boucle console
# =========================

if __name__ == "__main__":

    print("ğŸ©º PharmaBot Console")
    print("Tape 'exit' pour quitter\n")

    while True:
        user_input = input("ğŸ‘¤ DÃ©cris tes symptÃ´mes : ")

        if user_input.lower() == "exit":
            print("ğŸ‘‹ Au revoir!")
            break

        advice = get_pharma_advice(user_input)

        print("\nğŸ’Š PharmaBot :")
        print(advice)
        print("-" * 50)
